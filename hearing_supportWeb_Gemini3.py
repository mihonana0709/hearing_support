# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import av
import numpy as np
import threading
import queue
import logging
from scipy.signal import butter, lfilter

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    filename='hearing_support.log',
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "volume_history" not in st.session_state:
    st.session_state.volume_history = []
if "processing_thread" not in st.session_state:
    st.session_state.processing_thread = None

# ç¢ºå®Ÿã«ã‚­ãƒ¥ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹
if "audio_queue" not in st.session_state:
    st.session_state.audio_queue = queue.Queue()
if "volume_queue" not in st.session_state:
    st.session_state.volume_queue = queue.Queue()

# ãƒã‚¿ãƒ¼ãƒ¯ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¨­è¨ˆ
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band')
    return b, a

# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‡¦ç†
def bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)
    return y

# éŸ³å£°å‡¦ç†ã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§è¡Œã†ã‚¯ãƒ©ã‚¹
class AudioProcessingThread(threading.Thread):
    def __init__(self, audio_queue, volume_queue, gain_factor, low_freq_boost, high_freq_boost):
        super().__init__()
        self.audio_queue = audio_queue
        self.volume_queue = volume_queue
        self.gain_factor = gain_factor
        self.low_freq_boost = low_freq_boost
        self.high_freq_boost = high_freq_boost
        self.stop_event = threading.Event()
        logger.info("LOG: AudioProcessingThread åˆæœŸåŒ–å®Œäº†ã€‚")

    def run(self):
        logger.info("LOG: AudioProcessingThread é–‹å§‹ã€‚")
        while not self.stop_event.is_set():
            try:
                frame = self.audio_queue.get(timeout=1)
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’float64ã«å¤‰æ›ã—ã¦å‡¦ç†ã‚’é–‹å§‹
                audio_data_float = frame.to_ndarray().astype(np.float64)
                
                # ã‚¤ã‚³ãƒ©ã‚¤ã‚¶ãƒ¼å‡¦ç†
                if self.low_freq_boost != 0:
                    low_freq_data = bandpass_filter(audio_data_float.copy(), 20, 500, 16000)
                    audio_data_float += low_freq_data * self.low_freq_boost
                if self.high_freq_boost != 0:
                    high_freq_data = bandpass_filter(audio_data_float.copy(), 2000, 8000, 16000)
                    audio_data_float += high_freq_data * self.high_freq_boost
                
                # å…¨ä½“ã‚²ã‚¤ãƒ³ã‚’é©ç”¨
                amplified_data = audio_data_float * self.gain_factor
                
                if amplified_data.size > 0:
                    rms = np.sqrt(np.mean(np.square(amplified_data)))
                    self.volume_queue.put(rms)
                    logger.info(f"LOG: éŸ³å£°ãƒ‡ãƒ¼ã‚¿å–å¾—ã€RMS={rms:.2f}")

            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"LOG: éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼ -> {e}")
                # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åœæ­¢ã›ãšã€æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å¾…æ©Ÿ

    def stop(self):
        self.stop_event.set()
        logger.info("LOG: AudioProcessingThread åœæ­¢ä¿¡å·å—ä¿¡ã€‚")

# AudioProcessorBaseã‚’ç¶™æ‰¿ã—ãŸWebRTCç”¨ã®ã‚¯ãƒ©ã‚¹
class WebRtcAudioProcessor(AudioProcessorBase):
    def __init__(self, audio_queue):
        self.audio_queue = audio_queue
        logger.info("LOG: WebRtcAudioProcessor åˆæœŸåŒ–å®Œäº†ã€‚")

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        self.audio_queue.put(frame)
        return frame

# ---
### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³UI ###
st.title("ğŸ¤ è´è¦šã‚µãƒãƒ¼ãƒˆã‚¢ãƒ—ãƒª")
st.write("ãƒã‚¤ã‚¯éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¢—å¹…ãƒ»èª¿æ•´ã—ã€ã‚¤ãƒ¤ãƒ›ãƒ³ã‹ã‚‰å†ç”Ÿã—ã¾ã™ã€‚")

# ãƒ¡ã‚¤ãƒ³ç”»é¢ã«éŸ³é‡ãƒ»éŸ³è³ªèª¿æ•´ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’é…ç½®
st.markdown("### ğŸ”Š éŸ³å£°èª¿æ•´")
gain_slider = st.slider(
    "å…¨ä½“éŸ³é‡ï¼ˆã‚²ã‚¤ãƒ³ï¼‰",
    min_value=1.0,
    max_value=10.0,
    value=3.0,
    step=0.5,
    help="ãƒã‚¤ã‚¯ã§æ‹¾ã£ãŸéŸ³ã‚’å¢—å¹…ã™ã‚‹ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´ã—ã¾ã™ã€‚"
)

low_freq_boost_slider = st.slider(
    "ä½éŸ³åŸŸèª¿æ•´",
    min_value=-2.0,
    max_value=2.0,
    value=0.0,
    step=0.1,
    help="ä½éŸ³åŸŸï¼ˆã€œ500Hzï¼‰ã®éŸ³é‡ã‚’èª¿æ•´ã—ã¾ã™ã€‚ãƒã‚¤ã‚ºãŒæ°—ã«ãªã‚‹å ´åˆã¯ä¸‹ã’ã¦ãã ã•ã„ã€‚"
)

high_freq_boost_slider = st.slider(
    "é«˜éŸ³åŸŸèª¿æ•´",
    min_value=-2.0,
    max_value=2.0,
    value=0.0,
    step=0.1,
    help="é«˜éŸ³åŸŸï¼ˆ2kHzã€œ8kHzï¼‰ã®éŸ³é‡ã‚’èª¿æ•´ã—ã¾ã™ã€‚è´åŠ›ã«åˆã‚ã›ã¦ä¸Šã’ã‚‹ã¨èãå–ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚"
)

st.markdown("---")
st.markdown("### ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¬ãƒ™ãƒ«")

while not st.session_state.volume_queue.empty():
    st.session_state.volume_history.append(st.session_state.volume_queue.get())
    if len(st.session_state.volume_history) > 100:
        st.session_state.volume_history.pop(0)

if "webrtc_ctx" in st.session_state and st.session_state.webrtc_ctx.state.playing:
    st.line_chart(st.session_state.volume_history)
else:
    st.info("ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å¾…æ©Ÿä¸­ã§ã™...")


# webrtc_ctxã®åˆæœŸåŒ–ã‚’ try-except ã§å›²ã‚€
try:
    processor = WebRtcAudioProcessor(st.session_state.audio_queue)
    webrtc_ctx = webrtc_streamer(
        key="speech",
        mode=WebRtcMode.SENDRECV,
        audio_processor_factory=lambda: processor,
        media_stream_constraints={
            "audio": True,
            "video": False
        },
    )
    st.session_state.webrtc_ctx = webrtc_ctx

except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()


# ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®çŠ¶æ…‹è¡¨ç¤º
status_placeholder = st.empty()
if webrtc_ctx.state.playing:
    status_placeholder.info("ğŸ§ éŸ³å£°å¢—å¹…ä¸­...")
    if st.session_state.processing_thread is None or not st.session_state.processing_thread.is_alive():
        st.session_state.processing_thread = AudioProcessingThread(
            st.session_state.audio_queue, 
            st.session_state.volume_queue,
            gain_slider,
            low_freq_boost_slider,
            high_freq_boost_slider
        )
        st.session_state.processing_thread.start()
elif not webrtc_ctx.state.playing and st.session_state.processing_thread is not None:
    st.session_state.processing_thread.stop()
    st.session_state.processing_thread.join()
    st.session_state.processing_thread = None
    status_placeholder.info("ğŸ›‘ åœæ­¢ä¸­")
else:
    status_placeholder.info("ğŸ›‘ åœæ­¢ä¸­")
