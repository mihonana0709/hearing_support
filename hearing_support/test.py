# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase, get_devices
import vosk
import json
import os
import av # PyAVãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import threading
import numpy as np
import time
import logging

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Voskãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šï¼ˆäº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãŠãï¼‰
MODEL_PATH = "vosk-model-small-ja-0.22"

# èªè­˜å±¥æ­´ã®åˆæœŸåŒ–
if "history" not in st.session_state:
    st.session_state.history = []
if "is_listening" not in st.session_state:
    st.session_state.is_listening = False
if "recognizer" not in st.session_state:
    st.session_state.recognizer = None
if "model_loaded" not in st.session_state:
    st.session_state.model_loaded = False
if "volume_history" not in st.session_state:
    st.session_state.volume_history = []
if "start_time" not in st.session_state:
    st.session_state.start_time = time.time()
if "current_transcription" not in st.session_state:
    st.session_state.current_transcription = ""

# Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿é–¢æ•°
@st.cache_resource
def load_vosk_model():
    try:
        model = vosk.Model(MODEL_PATH)
        logger.info("LOG: Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return model
    except Exception as e:
        st.error(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        logger.error(f"LOG: Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

# Streamlitã®UIéƒ¨åˆ†
st.title("ğŸ¤ è´è¦šã‚µãƒãƒ¼ãƒˆã‚¢ãƒ—ãƒª")
st.write("ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—ã—ã¾ã™ã€‚")

# ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆã‚’å–å¾—
devices = get_devices()
audio_input_devices = [d for d in devices if d.kind == "audioinput"]
audio_output_devices = [d for d in devices if d.kind == "audiooutput"]

audio_input_labels = [d.label for d in audio_input_devices]
audio_output_labels = [d.label for d in audio_output_devices]

# ãƒ‡ãƒã‚¤ã‚¹é¸æŠã®ãŸã‚ã®ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹
audio_input_selected_label = st.selectbox(
    "ãƒã‚¤ã‚¯ã‚’é¸æŠ", audio_input_labels
)
audio_input_device_id = next((d.id for d in audio_input_devices if d.label == audio_input_selected_label), None)

# webrtc_streamerã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’é…ç½®
webrtc_ctx = webrtc_streamer(
    key="speech",
    mode=WebRtcMode.SENDONLY,  # éŸ³å£°ã®é€å—ä¿¡ã‚’åœæ­¢
    audio_receiver_size=2048,
    media_stream_constraints={
        "audio": {
            "deviceId": {"exact": audio_input_device_id}
        },
        "video": False
    },
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«UIè¦ç´ ã‚’é…ç½®
with st.sidebar:
    # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®ã‚°ãƒ©ãƒ•è¡¨ç¤º
    st.markdown("---")
    st.markdown("### ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¬ãƒ™ãƒ«")
    if webrtc_ctx.state.playing and st.session_state.volume_history:
        st.line_chart(st.session_state.volume_history)
    else:
        st.info("ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å¾…æ©Ÿä¸­ã§ã™...")

# ãƒ¡ã‚¤ãƒ³ç”»é¢ã«UIè¦ç´ ã‚’é…ç½®
# ãƒã‚¤ã‚¯ã®çŠ¶æ…‹è¡¨ç¤º
status_placeholder = st.empty()
if webrtc_ctx.state.playing:
    st.session_state.is_listening = True
    status_placeholder.info("ğŸ§ éŸ³å£°èªè­˜ä¸­...è©±ã—ã‹ã‘ã¦ãã ã•ã„")
else:
    st.session_state.is_listening = False
    status_placeholder.info("ğŸ›‘ åœæ­¢ä¸­")

# èªè­˜çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
st.markdown("### ğŸ“ èªè­˜çµæœ")
result_placeholder = st.empty()
if st.session_state.current_transcription:
    result_placeholder.write(st.session_state.current_transcription)
else:
    result_placeholder.info("ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

st.markdown("---")
st.markdown("### ğŸ“‹ å±¥æ­´")
if st.session_state.history:
    for line in reversed(st.session_state.history):
        st.write(f"- {line}")

# WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å‡¦ç†ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
if webrtc_ctx.audio_receiver:
    logger.info("LOG: webrtc_ctx.audio_receiverãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    if st.session_state.recognizer is None:
        try:
            vosk_model = load_vosk_model()
            if vosk_model:
                st.session_state.recognizer = vosk.KaldiRecognizer(vosk_model, 16000)
                logger.info("LOG: Voskèªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸã€‚")
        except Exception as e:
            st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
            logger.error(f"LOG: Voskèªè­˜ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
            st.session_state.is_listening = False
    
    try:
        while webrtc_ctx.state.playing:
            frames = webrtc_ctx.audio_receiver.get_frames(timeout=1)
            
            if frames:
                logger.info(f"LOG: {len(frames)} å€‹ã®éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚")
                for frame in frames:
                    audio_data = frame.to_ndarray()
                    
                    # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ã—ã€ã‚°ãƒ©ãƒ•å±¥æ­´ã‚’æ›´æ–°
                    rms = np.sqrt(np.mean(np.square(audio_data)))
                    st.session_state.volume_history.append(rms)
                    if len(st.session_state.volume_history) > 50:
                        st.session_state.volume_history.pop(0)
                    
                    # èªè­˜å‡¦ç†
                    if st.session_state.recognizer:
                        logger.info("LOG: Voskèªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¦ã„ã¾ã™ã€‚")
                        if st.session_state.recognizer.AcceptWaveform(audio_data.tobytes()):
                            result = st.session_state.recognizer.Result()
                            text = json.loads(result)["text"]
                            if text.strip():
                                st.session_state.history.append(text)
                                st.session_state.current_transcription = ""
                                logger.info(f"LOG: æœ€çµ‚çš„ãªæ–‡å­—èµ·ã“ã—çµæœ: {text}")
                        else:
                            partial_result = st.session_state.recognizer.PartialResult()
                            partial_text = json.loads(partial_result)["partial"]
                            if partial_text.strip():
                                st.session_state.current_transcription = partial_text
                                logger.info(f"LOG: éƒ¨åˆ†çš„ãªæ–‡å­—èµ·ã“ã—çµæœ: {partial_text}")
            else:
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå—ä¿¡ã•ã‚Œãªã„å ´åˆã§ã‚‚ãƒ«ãƒ¼ãƒ—ã‚’ç¶™ç¶š
                logger.info("LOG: ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå—ä¿¡ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                time.sleep(0.1)
    except Exception as e:
        logger.error(f"LOG: éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
