# ==========================
# å¿…è¦ãªé“å…·ï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰ã‚’å‘¼ã³å‡ºã™
# ==========================
import streamlit as st                        # streamlit â†’ ã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ãŸã‚ã®é“å…·
from streamlit_webrtc import (                # streamlit_webrtc â†’ ãƒã‚¤ã‚¯ã‚„éŸ³ã‚’æ‰±ã†ãŸã‚ã®é“å…·
    webrtc_streamer,                          # webrtc_streamer â†’ ãƒã‚¤ã‚¯ã®éŸ³ã‚’æ‹¾ã£ã¦ã‚¤ãƒ¤ãƒ›ãƒ³ã«å‡ºã™é“å…·
    WebRtcMode,                               # WebRtcMode â†’ ãƒã‚¤ã‚¯ã®ä½¿ã„æ–¹ã®ãƒ¢ãƒ¼ãƒ‰
    AudioProcessorBase                        # AudioProcessorBase â†’ éŸ³ã‚’åŠ å·¥ã™ã‚‹åŸºæœ¬ã®å‹
)
import av                                     # av â†’ éŸ³ã‚„å‹•ç”»ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†é“å…·
import numpy as np                            # numpy â†’ æ•°ã‚’è¨ˆç®—ã™ã‚‹é“å…·ï¼ˆè¶³ã™ãƒ»æ›ã‘ã‚‹ãƒ»å¹³å‡ãªã©ï¼‰
import threading                              # threading â†’ ã€ŒåŒæ™‚ã«å‹•ã‹ã™ã€ä»•çµ„ã¿ã‚’ä½œã‚‹é“å…·
import queue                                  # queue â†’ ã€Œé †ç•ªã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦ã¹ã‚‹ç®±ã€
import logging                                # logging â†’ è¨˜éŒ²ã‚’æ®‹ã™é“å…·
from scipy.signal import butter, lfilter      # scipy.signal â†’ éŸ³ã‚’åŠ å·¥ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼‰ã™ã‚‹é“å…·

# ==========================
# è¨˜éŒ²ã®è¨­å®šï¼ˆãƒ­ã‚°ï¼‰
# ==========================
logging.basicConfig(
    filename='hearing_support.log',           # filename â†’ è¨˜éŒ²ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰
    level=logging.INFO,                       # level â†’ ã©ã®ãã‚‰ã„ã®æƒ…å ±ã‚’æ®‹ã™ã‹ï¼ˆINFOä»¥ä¸Šï¼‰
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'  # è¨˜éŒ²ã®æ›¸ãæ–¹
)
logger = logging.getLogger(__name__)          # logger â†’ ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ å°‚ç”¨ã®è¨˜éŒ²ä¿‚

# ==========================
# ã‚¢ãƒ—ãƒªã®ä¸­ã§è¦šãˆã¦ãŠãã€ŒçŠ¶æ…‹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ï¼‰ã€
# ==========================
if "volume_history" not in st.session_state:  # volume_history â†’ éŸ³é‡ã®å‹•ãã‚’ä¿å­˜
    st.session_state.volume_history = []
if "processing_thread" not in st.session_state: # processing_thread â†’ éŸ³ã‚’åŠ å·¥ã™ã‚‹åˆ¥ã®å‹•ã
    st.session_state.processing_thread = None
if "audio_queue" not in st.session_state:     # audio_queue â†’ éŸ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚çš„ã«ç½®ãç®±
    st.session_state.audio_queue = queue.Queue()
if "volume_queue" not in st.session_state:    # volume_queue â†’ éŸ³é‡ã®æ•°å€¤ã‚’ä¸€æ™‚çš„ã«ç½®ãç®±
    st.session_state.volume_queue = queue.Queue()

# ==========================
# éŸ³ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§æ•´ãˆã‚‹é–¢æ•°
# ==========================
def butter_bandpass(lowcut, highcut, fs, order=5):
    # lowcut â†’ ä¸‹ã®éŸ³ã®åˆ‡ã‚‹ä½ç½®
    # highcut â†’ ä¸Šã®éŸ³ã®åˆ‡ã‚‹ä½ç½®
    # fs â†’ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°ï¼ˆ1ç§’ã«ä½•å›éŸ³ã‚’æ¸¬ã‚‹ã‹ï¼‰
    nyquist = 0.5 * fs                        # nyquist â†’ å‘¨æ³¢æ•°ã®åŠåˆ†ï¼ˆç†è«–ä¸Šã®é™ç•Œï¼‰
    low = lowcut / nyquist                    # low â†’ ä¸‹ã®éŸ³ã®å‰²åˆ
    high = highcut / nyquist                  # high â†’ ä¸Šã®éŸ³ã®å‰²åˆ
    b, a = butter(order, [low, high], btype='band') # butter â†’ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ä½œã‚‹
    return b, a

def bandpass_filter(data, lowcut, highcut, fs, order=5):
    # data â†’ éŸ³ã®ãƒ‡ãƒ¼ã‚¿
    b, a = butter_bandpass(lowcut, highcut, fs, order=order) # b,a â†’ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ææ–™
    y = lfilter(b, a, data)                   # lfilter â†’ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‹ã‘ã‚‹
    return y

# ==========================
# éŸ³ã®èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ•°å€¤ã®è¨­å®šï¼‰
# ==========================
class AudioParams:
    def __init__(self):
        self.gain_factor = 3.0                # gain_factor â†’ éŸ³é‡ã‚’ä½•å€ã«ã™ã‚‹ã‹
        self.low_freq_boost = 0.0             # low_freq_boost â†’ ä½ã„éŸ³ã‚’ã©ã‚Œãã‚‰ã„å¼·ãã™ã‚‹ã‹
        self.high_freq_boost = 0.0            # high_freq_boost â†’ é«˜ã„éŸ³ã‚’ã©ã‚Œãã‚‰ã„å¼·ãã™ã‚‹ã‹
        self.target_rms = 5000                # target_rms â†’ è‡ªå‹•éŸ³é‡èª¿æ•´ã®ç›®æ¨™å€¤

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«éŸ³ã®èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
if "audio_params" not in st.session_state:
    st.session_state.audio_params = AudioParams()

# ==========================
# éŸ³ã‚’åŠ å·¥ã™ã‚‹ã€Œåˆ¥ã®å‹•ãï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ã€
# ==========================
class AudioProcessingThread(threading.Thread):
    def __init__(self, audio_queue, volume_queue, params):
        super().__init__()
        self.audio_queue = audio_queue        # éŸ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹ç®±
        self.volume_queue = volume_queue      # éŸ³é‡ã®æ•°å€¤ã‚’å…¥ã‚Œã‚‹ç®±
        self.params = params                  # éŸ³ã®è¨­å®šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
        self.stop_event = threading.Event()   # æ­¢ã‚ã‚‹ãŸã‚ã®ã‚¹ã‚¤ãƒƒãƒ

    def run(self):
        while not self.stop_event.is_set():   # æ­¢ã‚ã‚‹ã‚¹ã‚¤ãƒƒãƒãŒæŠ¼ã•ã‚Œã¦ã„ãªã‘ã‚Œã°å‹•ã
            try:
                frame = self.audio_queue.get(timeout=1) # éŸ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’1ã¤å–ã‚Šå‡ºã™
                audio_data_float = frame.to_ndarray().astype(np.float64) # æ•°å­—ã«å¤‰æ›

                # è¨­å®šï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã‚’èª­ã¿è¾¼ã¿
                gain_factor = self.params.gain_factor
                low_freq_boost = self.params.low_freq_boost
                high_freq_boost = self.params.high_freq_boost
                target_rms = self.params.target_rms

                # ä½éŸ³ã®å¼·èª¿
                if low_freq_boost != 0:
                    low_freq_data = bandpass_filter(audio_data_float.copy(), 20, 500, 16000)
                    audio_data_float += low_freq_data * low_freq_boost

                # é«˜éŸ³ã®å¼·èª¿
                if high_freq_boost != 0:
                    # high_freq_data = bandpass_filter(audio_data_float.copy(), 2000, 8000, 16000)
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®è¨­è¨ˆã«ãŠã„ã¦ã€ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªå‘¨æ³¢æ•°ã‚’ 0 ã‹ã‚‰ 1 ã®é–“ã®å€¤ã«å¤‰æ›´ã—ã¾ã™ã€‚
                    # 0.1 ã¯ã€ä¸‹é™ã®å‘¨æ³¢æ•°ã‚’æ„å‘³ã—ã¾ã™ã€‚
                    # 0.5 ã¯ã€ä¸Šé™ã®å‘¨æ³¢æ•°ã‚’æ„å‘³ã—ã¾ã™ã€‚
                    high_freq_data = bandpass_filter(audio_data_float.copy(), 0.1, 0.5, 16000)
                    audio_data_float += high_freq_data * high_freq_boost

                # è‡ªå‹•éŸ³é‡èª¿æ•´ï¼ˆAGCï¼‰
                rms = np.sqrt(np.mean(np.square(audio_data_float))) + 1e-6
                agc_gain = target_rms / rms
                audio_data_float *= agc_gain

                # éŸ³é‡ã‚’å…¨ä½“çš„ã«å¤§ããã™ã‚‹
                amplified_data = audio_data_float * gain_factor

                # éŸ³ãŒå¤§ãã™ããªã„ã‚ˆã†ã«åˆ‡ã‚‹
                amplified_data = np.clip(amplified_data, -32767, 32767)

                # ä»Šã®éŸ³é‡ã‚’ç®±ã«å…¥ã‚Œã‚‹ï¼ˆã‚°ãƒ©ãƒ•ç”¨ï¼‰
                rms_after = np.sqrt(np.mean(np.square(amplified_data)))
                self.volume_queue.put(rms_after)

            except queue.Empty:               # ç®±ãŒç©ºã£ã½ã ã£ãŸã‚‰
                continue                      # ä½•ã‚‚ã›ãšæ¬¡ã¸é€²ã‚€

    def stop(self):                           # æ­¢ã‚ã‚‹é–¢æ•°
        self.stop_event.set()

# ==========================
# WebRTCï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ã¨ã‚¤ãƒ¤ãƒ›ãƒ³å‡ºåŠ›ï¼‰
# ==========================
class WebRtcAudioProcessor(AudioProcessorBase):
    def __init__(self, audio_queue):
        self.audio_queue = audio_queue

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        self.audio_queue.put(frame)           # éŸ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç®±ã«å…¥ã‚Œã‚‹
        return frame                          # ãã®ã¾ã¾ã‚¤ãƒ¤ãƒ›ãƒ³ã«å‡ºã™

# ==========================
# Streamlitã§ç”»é¢ã‚’ä½œã‚‹
# ==========================
st.title("ğŸ¤ è´è¦šã‚µãƒãƒ¼ãƒˆã‚¢ãƒ—ãƒª")  # ã‚¢ãƒ—ãƒªã®åå‰
st.write("ãƒã‚¤ã‚¯ã®éŸ³ã‚’å¤§ããã—ã¦ã€ã‚¤ãƒ¤ãƒ›ãƒ³ã‹ã‚‰èã“ãˆã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚")

# éŸ³é‡ãƒ»éŸ³è³ªã‚’èª¿æ•´ã™ã‚‹ã¤ã¾ã¿ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ï¼‰
st.markdown("### ğŸ”Š éŸ³ã®èª¿æ•´")
st.session_state.audio_params.gain_factor = st.slider("å…¨ä½“éŸ³é‡ï¼ˆã‚²ã‚¤ãƒ³ï¼‰", 0.1, 200.0, 3.0, 0.1)
st.session_state.audio_params.low_freq_boost = st.slider("ä½éŸ³ã‚’å¼·ãã™ã‚‹", -2.0, 2.0, 0.0, 0.1)
st.session_state.audio_params.high_freq_boost = st.slider("é«˜éŸ³ã‚’å¼·ãã™ã‚‹", -2.0, 2.0, 0.0, 0.1)
st.session_state.audio_params.target_rms = st.slider("è‡ªå‹•éŸ³é‡ã®ç›®æ¨™", 1000, 50000, 5000, 500)

# ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³ã‚’å–ã£ã¦ã€ã‚¤ãƒ¤ãƒ›ãƒ³ã«å‡ºã™
try:
    processor = WebRtcAudioProcessor(st.session_state.audio_queue)
    webrtc_ctx = webrtc_streamer(
        key="speech",                         # ã“ã®å‡¦ç†ã®åå‰
        mode=WebRtcMode.SENDRECV,             # ãƒã‚¤ã‚¯ã‹ã‚‰å–ã£ã¦å‡ºã™ãƒ¢ãƒ¼ãƒ‰
        audio_processor_factory=lambda: processor, # éŸ³ã‚’åŠ å·¥ã™ã‚‹å·¥å ´
        media_stream_constraints={
            "audio": True,                    # éŸ³ã‚’ä½¿ã†
            "video": False                    # æ˜ åƒã¯ä½¿ã‚ãªã„
        },
    )
    st.session_state.webrtc_ctx = webrtc_ctx
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# éŸ³ã‚’åŠ å·¥ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ã®é–‹å§‹ã¨åœæ­¢
if webrtc_ctx.state.playing:
    if st.session_state.processing_thread is None or not st.session_state.processing_thread.is_alive():
        st.session_state.processing_thread = AudioProcessingThread(
            st.session_state.audio_queue, 
            st.session_state.volume_queue,
            st.session_state.audio_params
        )
        st.session_state.processing_thread.start()
else:
    if st.session_state.processing_thread is not None:
        st.session_state.processing_thread.stop()
        st.session_state.processing_thread.join()
        st.session_state.processing_thread = None

# éŸ³é‡ã®ã‚°ãƒ©ãƒ•ã‚’å‡ºã™
st.markdown("---")
st.markdown("### ğŸ“Š éŸ³é‡ã®ã‚°ãƒ©ãƒ•")

while not st.session_state.volume_queue.empty():
    st.session_state.volume_history.append(st.session_state.volume_queue.get())
    if len(st.session_state.volume_history) > 100:
        st.session_state.volume_history.pop(0)

if "webrtc_ctx" in st.session_state and st.session_state.webrtc_ctx.state.playing:
    st.line_chart(st.session_state.volume_history) # ã‚°ãƒ©ãƒ•ã«æã
else:
    st.info("ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å¾…ã£ã¦ã„ã¾ã™â€¦")
