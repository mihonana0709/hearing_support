# ==========================
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ==========================
import streamlit as st                        # Webã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from streamlit_webrtc import (                # ãƒã‚¤ã‚¯ã‚„ã‚«ãƒ¡ãƒ©ã‚’æ‰±ã†æ‹¡å¼µãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    webrtc_streamer, WebRtcMode, AudioProcessorBase
)
import av                                     # éŸ³å£°/å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ‰±ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import numpy as np                            # æ•°å€¤è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆè¡Œåˆ—ãƒ»é…åˆ—ï¼‰
import threading                              # ä¸¦åˆ—å‡¦ç†ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰å®Ÿè¡Œï¼‰
import queue                                  # ã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ãŸã‚ã®ã‚­ãƒ¥ãƒ¼
import logging                                # ãƒ­ã‚°å‡ºåŠ›ç”¨
from scipy.signal import butter, lfilter      # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆéŸ³åŸŸèª¿æ•´ï¼‰ç”¨

# ==========================
# ãƒ­ã‚°ã®è¨­å®š
# ==========================
logging.basicConfig(
    filename='hearing_support.log',           # ãƒ­ã‚°ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å
    level=logging.INFO,                       # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ï¼ˆINFOä»¥ä¸Šã‚’è¨˜éŒ²ï¼‰
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)          # ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ å°‚ç”¨ã®ãƒ­ã‚¬ãƒ¼ã‚’ä½œæˆ

# ==========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ï¼ˆçŠ¶æ…‹ä¿æŒï¼‰
# ==========================
if "volume_history" not in st.session_state:  # éŸ³é‡ã®å±¥æ­´ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜
    st.session_state.volume_history = []
if "processing_thread" not in st.session_state: # éŸ³å£°å‡¦ç†ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä¿æŒ
    st.session_state.processing_thread = None
if "audio_queue" not in st.session_state:     # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ä¿å­˜ã™ã‚‹ã‚­ãƒ¥ãƒ¼
    st.session_state.audio_queue = queue.Queue()
if "volume_queue" not in st.session_state:    # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ¥ãƒ¼
    st.session_state.volume_queue = queue.Queue()

# ==========================
# éŸ³å£°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢æ•°
# ==========================
def butter_bandpass(lowcut, highcut, fs, order=5):
    # lowcut: ä¸‹é™å‘¨æ³¢æ•°
    # highcut: ä¸Šé™å‘¨æ³¢æ•°
    # fs: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°
    nyquist = 0.5 * fs
    low = lowcut / nyquist
    high = highcut / nyquist
    b, a = butter(order, [low, high], btype='band') # ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­è¨ˆ
    return b, a

def bandpass_filter(data, lowcut, highcut, fs, order=5):
    # data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)                   # ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    return y

# ==========================
# éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ã‚¯ãƒ©ã‚¹
# ==========================
class AudioParams:
    def __init__(self):
        self.gain_factor = 3.0                # å…¨ä½“éŸ³é‡ã®å€ç‡
        self.low_freq_boost = 0.0             # ä½éŸ³åŸŸã®å¼·èª¿ãƒ¬ãƒ™ãƒ«
        self.high_freq_boost = 0.0            # é«˜éŸ³åŸŸã®å¼·èª¿ãƒ¬ãƒ™ãƒ«
        self.target_rms = 5000                # AGC(è‡ªå‹•éŸ³é‡èª¿æ•´)ã®ç›®æ¨™éŸ³é‡ãƒ¬ãƒ™ãƒ«

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿æŒ
if "audio_params" not in st.session_state:
    st.session_state.audio_params = AudioParams()

# ==========================
# éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¯ãƒ©ã‚¹
# ==========================
class AudioProcessingThread(threading.Thread):
    def __init__(self, audio_queue, volume_queue, params):
        super().__init__()
        self.audio_queue = audio_queue
        self.volume_queue = volume_queue
        self.params = params                  # éŸ³å£°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‚ç…§
        self.stop_event = threading.Event()

    def run(self):
        while not self.stop_event.is_set():   # åœæ­¢ãƒ•ãƒ©ã‚°ãŒç«‹ã¤ã¾ã§å‡¦ç†ã‚’ç¶šã‘ã‚‹
            try:
                frame = self.audio_queue.get(timeout=1) # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
                audio_data_float = frame.to_ndarray().astype(np.float64) # æ•°å€¤åŒ–

                # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ ---
                gain_factor = self.params.gain_factor
                low_freq_boost = self.params.low_freq_boost
                high_freq_boost = self.params.high_freq_boost
                target_rms = self.params.target_rms

                # --- EQå‡¦ç†ï¼ˆä½éŸ³/é«˜éŸ³è£œæ­£ï¼‰ ---
                if low_freq_boost != 0:
                    low_freq_data = bandpass_filter(audio_data_float.copy(), 20, 500, 16000)
                    audio_data_float += low_freq_data * low_freq_boost
                if high_freq_boost != 0:
                    high_freq_data = bandpass_filter(audio_data_float.copy(), 2000, 8000, 16000)
                    audio_data_float += high_freq_data * high_freq_boost

                # --- AGCï¼ˆè‡ªå‹•éŸ³é‡èª¿æ•´ï¼‰ ---
                rms = np.sqrt(np.mean(np.square(audio_data_float))) + 1e-6
                agc_gain = target_rms / rms
                audio_data_float *= agc_gain

                # --- ã‚²ã‚¤ãƒ³ï¼ˆéŸ³é‡èª¿æ•´ï¼‰ ---
                amplified_data = audio_data_float * gain_factor

                # --- ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢ ---
                amplified_data = np.clip(amplified_data, -32767, 32767)

                # --- RMSã‚’ãƒ¢ãƒ‹ã‚¿ç”¨ã«ä¿å­˜ ---
                rms_after = np.sqrt(np.mean(np.square(amplified_data)))
                self.volume_queue.put(rms_after)

            except queue.Empty:
                continue

    def stop(self):
        self.stop_event.set()

# ==========================
# WebRTCã®éŸ³å£°å‡¦ç†ã‚¯ãƒ©ã‚¹
# ==========================
class WebRtcAudioProcessor(AudioProcessorBase):
    def __init__(self, audio_queue):
        self.audio_queue = audio_queue

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        self.audio_queue.put(frame)           # éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ¥ãƒ¼ã«å…¥ã‚Œã‚‹
        return frame                          # ãã®ã¾ã¾å‡ºåŠ›ã«å›ã™

# ==========================
# Streamlit UIéƒ¨åˆ†
# ==========================
st.title("ğŸ¤ è´è¦šã‚µãƒãƒ¼ãƒˆã‚¢ãƒ—ãƒª")
st.write("ãƒã‚¤ã‚¯éŸ³å£°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å¢—å¹…ãƒ»èª¿æ•´ã—ã€ã‚¤ãƒ¤ãƒ›ãƒ³ã‹ã‚‰å†ç”Ÿã—ã¾ã™ã€‚")

# --- éŸ³é‡ãƒ»éŸ³è³ªèª¿æ•´ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ ---
st.markdown("### ğŸ”Š éŸ³å£°èª¿æ•´")
st.session_state.audio_params.gain_factor = st.slider(
    "å…¨ä½“éŸ³é‡ï¼ˆã‚²ã‚¤ãƒ³ï¼‰", 0.1, 200.0, 3.0, 0.1
)
st.session_state.audio_params.low_freq_boost = st.slider(
    "ä½éŸ³åŸŸèª¿æ•´", -2.0, 2.0, 0.0, 0.1
)
st.session_state.audio_params.high_freq_boost = st.slider(
    "é«˜éŸ³åŸŸèª¿æ•´", -2.0, 2.0, 0.0, 0.1
)
st.session_state.audio_params.target_rms = st.slider(
    "AGC ç›®æ¨™éŸ³é‡ãƒ¬ãƒ™ãƒ«", 1000, 50000, 5000, 500
)

# --- WebRTCï¼ˆãƒã‚¤ã‚¯å…¥åŠ› + ã‚¤ãƒ¤ãƒ›ãƒ³å‡ºåŠ›ï¼‰ ---
try:
    processor = WebRtcAudioProcessor(st.session_state.audio_queue)
    webrtc_ctx = webrtc_streamer(
        key="speech",
        mode=WebRtcMode.SENDRECV,            # åŒæ–¹å‘ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›â†’å‡ºåŠ›å†ç”Ÿï¼‰
        audio_processor_factory=lambda: processor,
        media_stream_constraints={
            "audio": True,                   # éŸ³å£°ã®ã¿
            "video": False
        },
    )
    st.session_state.webrtc_ctx = webrtc_ctx
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- éŸ³å£°å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã®é–‹å§‹/åœæ­¢ ---
if webrtc_ctx.state.playing:
    if st.session_state.processing_thread is None or not st.session_state.processing_thread.is_alive():
        st.session_state.processing_thread = AudioProcessingThread(
            st.session_state.audio_queue, 
            st.session_state.volume_queue,
            st.session_state.audio_params
        )
        st.session_state.processing_thread.start()
else:
    if st.session_state.processing_thread is not None:
        st.session_state.processing_thread.stop()
        st.session_state.processing_thread.join()
        st.session_state.processing_thread = None

# --- éŸ³é‡ã‚°ãƒ©ãƒ• ---
st.markdown("---")
st.markdown("### ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³é‡ãƒ¬ãƒ™ãƒ«")

while not st.session_state.volume_queue.empty():
    st.session_state.volume_history.append(st.session_state.volume_queue.get())
    if len(st.session_state.volume_history) > 100:
        st.session_state.volume_history.pop(0)

if "webrtc_ctx" in st.session_state and st.session_state.webrtc_ctx.state.playing:
    st.line_chart(st.session_state.volume_history)
else:
    st.info("ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å¾…æ©Ÿä¸­ã§ã™...")
